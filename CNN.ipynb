{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images Dimensions\n",
    "img_width, img_height = 200, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'Downloads/video/data/training'\n",
    "validation_data_dir = 'Downloads/video/data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 5552\n",
    "nb_validation_samples = 1000\n",
    "epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = TensorBoard(log_dir='./grafik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale Testing Data\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5552 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Train Data Generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Testing Data Generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction Layer\n",
    "inputs = Input(shape=(img_width, img_height, 3))\n",
    "conv_layer = Conv2D(16, (5, 5), strides=(3,3), activation='relu')(inputs) \n",
    "conv_layer = ZeroPadding2D(padding=(1,1))(conv_layer) \n",
    "conv_layer = Conv2D(32, (5, 5), strides=(3,3), activation='relu')(conv_layer) \n",
    "conv_layer = MaxPooling2D((2, 2))(conv_layer) \n",
    "conv_layer = Conv2D(64, (3, 3), strides=(1,1), activation='relu')(conv_layer) \n",
    "conv_layer = Conv2D(64, (3, 3), strides=(1,1), activation='relu')(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Layer\n",
    "flatten = Flatten()(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connected Layer\n",
    "fc_layer = Dense(128, activation='relu')(flatten)\n",
    "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
    "fc_layer = Dense(32, activation='relu')(fc_layer)\n",
    "outputs = Dense(5, activation='softmax')(fc_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 66, 66, 16)        1216      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 68, 68, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 481,509\n",
      "Trainable params: 481,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print Model Summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43/43 [==============================] - 121s 3s/step - loss: 1.6055 - acc: 0.2911 - val_loss: 1.5089 - val_acc: 0.3984\n",
      "Epoch 2/50\n",
      "43/43 [==============================] - 119s 3s/step - loss: 1.3067 - acc: 0.5100 - val_loss: 0.8528 - val_acc: 0.7087\n",
      "Epoch 3/50\n",
      "43/43 [==============================] - 118s 3s/step - loss: 0.5976 - acc: 0.7968 - val_loss: 0.0946 - val_acc: 0.9702\n",
      "Epoch 4/50\n",
      "43/43 [==============================] - 118s 3s/step - loss: 0.4006 - acc: 0.8934 - val_loss: 0.2105 - val_acc: 0.9897\n",
      "Epoch 5/50\n",
      "43/43 [==============================] - 117s 3s/step - loss: 0.1251 - acc: 0.9685 - val_loss: 0.1905 - val_acc: 0.9220\n",
      "Epoch 6/50\n",
      "43/43 [==============================] - 118s 3s/step - loss: 0.2584 - acc: 0.9346 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "43/43 [==============================] - 120s 3s/step - loss: 0.1065 - acc: 0.9742 - val_loss: 0.0044 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "43/43 [==============================] - 117s 3s/step - loss: 0.5662 - acc: 0.9581 - val_loss: 8.8763e-04 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "43/43 [==============================] - 117s 3s/step - loss: 0.0184 - acc: 0.9948 - val_loss: 0.0389 - val_acc: 0.9688\n",
      "Epoch 10/50\n",
      "43/43 [==============================] - 122s 3s/step - loss: 0.1219 - acc: 0.9742 - val_loss: 3.4544e-04 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "43/43 [==============================] - 115s 3s/step - loss: 0.0857 - acc: 0.9740 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "43/43 [==============================] - 119s 3s/step - loss: 0.0196 - acc: 0.9930 - val_loss: 0.0443 - val_acc: 0.9839\n",
      "Epoch 13/50\n",
      "43/43 [==============================] - 122s 3s/step - loss: 0.1629 - acc: 0.9823 - val_loss: 1.4941e-04 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "43/43 [==============================] - 121s 3s/step - loss: 0.0151 - acc: 0.9951 - val_loss: 4.8872e-05 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "43/43 [==============================] - 121s 3s/step - loss: 0.0732 - acc: 0.9860 - val_loss: 3.2158e-05 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "43/43 [==============================] - 113s 3s/step - loss: 0.0083 - acc: 0.9972 - val_loss: 1.6504e-05 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "43/43 [==============================] - 103s 2s/step - loss: 0.2175 - acc: 0.9760 - val_loss: 2.5887e-05 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "43/43 [==============================] - 102s 2s/step - loss: 0.0017 - acc: 0.9994 - val_loss: 4.8984e-06 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "43/43 [==============================] - 103s 2s/step - loss: 0.0988 - acc: 0.9833 - val_loss: 7.6553e-07 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "43/43 [==============================] - 101s 2s/step - loss: 0.1275 - acc: 0.9819 - val_loss: 4.0457e-05 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "43/43 [==============================] - 101s 2s/step - loss: 3.3355e-04 - acc: 1.0000 - val_loss: 1.2918e-05 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "43/43 [==============================] - 99s 2s/step - loss: 0.0347 - acc: 0.9906 - val_loss: 4.0754e-05 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "43/43 [==============================] - 99s 2s/step - loss: 0.0454 - acc: 0.9934 - val_loss: 6.2700e-04 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "43/43 [==============================] - 100s 2s/step - loss: 7.6266e-04 - acc: 1.0000 - val_loss: 9.0790e-06 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "43/43 [==============================] - 111s 3s/step - loss: 0.0583 - acc: 0.9906 - val_loss: 6.4261e-08 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "43/43 [==============================] - 105s 2s/step - loss: 8.4101e-05 - acc: 1.0000 - val_loss: 2.7008e-08 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 0.0152 - acc: 0.9969 - val_loss: 5.5507e-07 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "43/43 [==============================] - 91s 2s/step - loss: 0.1232 - acc: 0.9813 - val_loss: 1.9769e-05 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "43/43 [==============================] - 89s 2s/step - loss: 2.2263e-04 - acc: 1.0000 - val_loss: 6.8918e-08 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "43/43 [==============================] - 89s 2s/step - loss: 0.3984 - acc: 0.9854 - val_loss: 5.9603e-07 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 1.0510e-04 - acc: 1.0000 - val_loss: 6.5193e-09 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "43/43 [==============================] - 89s 2s/step - loss: 3.5181e-06 - acc: 1.0000 - val_loss: 8.0237e-09 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 0.1877 - acc: 0.9841 - val_loss: 1.6298e-07 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 0.0021 - acc: 0.9993 - val_loss: 8.3819e-09 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 8.5873e-06 - acc: 1.0000 - val_loss: 8.1956e-08 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "43/43 [==============================] - 89s 2s/step - loss: 0.1233 - acc: 0.9867 - val_loss: 1.6764e-08 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "43/43 [==============================] - 91s 2s/step - loss: 0.0025 - acc: 0.9989 - val_loss: 5.5879e-08 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 0.1291 - acc: 0.9871 - val_loss: 4.4703e-08 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 4.1235e-05 - acc: 1.0000 - val_loss: 2.7940e-09 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 0.7280 - acc: 0.9699 - val_loss: 9.1699e-09 - val_acc: 0.9977\n",
      "Epoch 41/50\n",
      "43/43 [==============================] - 89s 2s/step - loss: 0.0033 - acc: 0.9991 - val_loss: 1.2365e-05 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "43/43 [==============================] - 91s 2s/step - loss: 0.0553 - acc: 0.9913 - val_loss: 3.0005e-06 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "43/43 [==============================] - 91s 2s/step - loss: 1.8333e-04 - acc: 1.0000 - val_loss: 1.8626e-08 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "43/43 [==============================] - 95s 2s/step - loss: 1.6864e-05 - acc: 1.0000 - val_loss: 4.1909e-08 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "43/43 [==============================] - 90s 2s/step - loss: 1.4597e-06 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "43/43 [==============================] - 103s 2s/step - loss: 0.4113 - acc: 0.9845 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "43/43 [==============================] - 108s 3s/step - loss: 1.6373e-05 - acc: 1.0000 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "43/43 [==============================] - 100s 2s/step - loss: 0.3140 - acc: 0.9817 - val_loss: 5.7312e-09 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "43/43 [==============================] - 103s 2s/step - loss: 0.0064 - acc: 0.9991 - val_loss: 2.8126e-07 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "43/43 [==============================] - 106s 2s/step - loss: 0.0129 - acc: 0.9974 - val_loss: 6.2769e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cf3e181828>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size, \n",
    "    callbacks=[callbacks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('wajah.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2764), started 0:01:23 ago. (Use '!kill 2764' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4e7242a6d7dae333\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4e7242a6d7dae333\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir grafik/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('wajah.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = 'Downloads/video/data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = pd.DataFrame(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.42874077e-08 6.00275143e-07 1.04027143e-11 2.26475103e-10\n",
      "  9.99999404e-01]\n",
      " [3.66769393e-10 3.24700835e-08 6.36293115e-14 3.77352527e-13\n",
      "  1.00000000e+00]\n",
      " [1.51093160e-09 6.26804280e-08 1.74357517e-13 7.76214054e-13\n",
      "  9.99999881e-01]\n",
      " ...\n",
      " [1.00000000e+00 9.96670225e-26 0.00000000e+00 4.42271756e-32\n",
      "  8.37702518e-36]\n",
      " [1.00000000e+00 1.02244854e-25 0.00000000e+00 2.86523222e-32\n",
      "  5.87987024e-36]\n",
      " [1.00000000e+00 8.35722320e-24 4.39414912e-38 2.76525352e-29\n",
      "  1.20539580e-33]]\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Nessie Judge         David        Hansol        Arnold   Joko Widodo\n",
      "0    1.428741e-08  6.002751e-07  1.040271e-11  2.264751e-10  9.999994e-01\n",
      "1    3.667694e-10  3.247008e-08  6.362931e-14  3.773525e-13  1.000000e+00\n",
      "2    1.510932e-09  6.268043e-08  1.743575e-13  7.762141e-13  9.999999e-01\n",
      "3    6.382915e-10  1.336836e-08  1.476896e-14  1.193507e-14  1.000000e+00\n",
      "4    6.565774e-11  3.210286e-09  6.888510e-16  1.079547e-15  1.000000e+00\n",
      "..            ...           ...           ...           ...           ...\n",
      "995  1.000000e+00  8.677511e-25  0.000000e+00  1.247182e-30  1.152581e-34\n",
      "996  1.000000e+00  1.758156e-24  0.000000e+00  3.081274e-30  2.408811e-34\n",
      "997  1.000000e+00  9.966702e-26  0.000000e+00  4.422718e-32  8.377025e-36\n",
      "998  1.000000e+00  1.022449e-25  0.000000e+00  2.865232e-32  5.879870e-36\n",
      "999  1.000000e+00  8.357223e-24  4.394149e-38  2.765254e-29  1.205396e-33\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "face.columns = [ 'Nessie Judge', 'David', 'Hansol', 'Arnold', 'Joko Widodo' ]\n",
    "print(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "face.to_excel(\"face.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse as arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
